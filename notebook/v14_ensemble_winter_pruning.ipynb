{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md_imports",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell_imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\conda_envs\\nitor_kuas\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import os, json\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from scipy.optimize import minimize as sp_minimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_configs",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell_configs",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path  = '../data/train.csv'\n",
    "test_path   = '../data/test_for_participants.csv'\n",
    "sample_path = '../data/sample_submission.csv'\n",
    "\n",
    "VAL_PHYSICS_START = '2024-09-01'\n",
    "VAL_PHYSICS_END   = '2025-01-01'\n",
    "VAL_RECENCY_START = '2025-06-01'\n",
    "\n",
    "SEED     = 42\n",
    "N_TRIALS = 25\n",
    "\n",
    "os.makedirs('../models/v14/', exist_ok=True)\n",
    "os.makedirs('../submissions/',  exist_ok=True)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_data",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell_data",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>market</th>\n",
       "      <th>global_horizontal_irradiance</th>\n",
       "      <th>diffuse_horizontal_irradiance</th>\n",
       "      <th>direct_normal_irradiance</th>\n",
       "      <th>cloud_cover_total</th>\n",
       "      <th>cloud_cover_low</th>\n",
       "      <th>cloud_cover_mid</th>\n",
       "      <th>cloud_cover_high</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_80m</th>\n",
       "      <th>wind_direction_80m</th>\n",
       "      <th>wind_gust_speed_10m</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>solar_forecast</th>\n",
       "      <th>wind_forecast</th>\n",
       "      <th>load_forecast</th>\n",
       "      <th>delivery_start</th>\n",
       "      <th>delivery_end</th>\n",
       "      <th>is_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.913</td>\n",
       "      <td>Market A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.253719</td>\n",
       "      <td>245.501450</td>\n",
       "      <td>25.199999</td>\n",
       "      <td>15.077082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24050.1</td>\n",
       "      <td>38163.0100</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.839</td>\n",
       "      <td>Market A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.918108</td>\n",
       "      <td>242.241547</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>14.186923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23886.3</td>\n",
       "      <td>37379.1898</td>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>-1.107</td>\n",
       "      <td>Market A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.983196</td>\n",
       "      <td>224.999893</td>\n",
       "      <td>21.240000</td>\n",
       "      <td>12.413477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23366.5</td>\n",
       "      <td>36336.8303</td>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.035</td>\n",
       "      <td>Market A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.218153</td>\n",
       "      <td>229.600174</td>\n",
       "      <td>16.199999</td>\n",
       "      <td>10.483357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22829.8</td>\n",
       "      <td>35337.7595</td>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.829</td>\n",
       "      <td>Market A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.210381</td>\n",
       "      <td>244.113022</td>\n",
       "      <td>18.359999</td>\n",
       "      <td>11.918120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22347.6</td>\n",
       "      <td>34474.3403</td>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>2023-01-01 05:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target    market  global_horizontal_irradiance  \\\n",
       "0   0  -1.913  Market A                           0.0   \n",
       "1   5  -0.839  Market A                           0.0   \n",
       "2  10  -1.107  Market A                           0.0   \n",
       "3  15   0.035  Market A                           0.0   \n",
       "4  20  -0.829  Market A                           0.0   \n",
       "\n",
       "   diffuse_horizontal_irradiance  direct_normal_irradiance  cloud_cover_total  \\\n",
       "0                            0.0                       0.0                2.0   \n",
       "1                            0.0                       0.0               15.0   \n",
       "2                            0.0                       0.0               17.0   \n",
       "3                            0.0                       0.0               16.0   \n",
       "4                            0.0                       0.0               10.0   \n",
       "\n",
       "   cloud_cover_low  cloud_cover_mid  cloud_cover_high  ...  wind_speed_80m  \\\n",
       "0              0.0              0.0               2.0  ...       31.253719   \n",
       "1              0.0              0.0              15.0  ...       30.918108   \n",
       "2              0.0              0.0              17.0  ...       26.983196   \n",
       "3              0.0              0.0              16.0  ...       22.218153   \n",
       "4              0.0              0.0              10.0  ...       27.210381   \n",
       "\n",
       "   wind_direction_80m  wind_gust_speed_10m  wind_speed_10m  solar_forecast  \\\n",
       "0          245.501450            25.199999       15.077082             0.0   \n",
       "1          242.241547            23.400000       14.186923             0.0   \n",
       "2          224.999893            21.240000       12.413477             0.0   \n",
       "3          229.600174            16.199999       10.483357             0.0   \n",
       "4          244.113022            18.359999       11.918120             0.0   \n",
       "\n",
       "   wind_forecast  load_forecast      delivery_start        delivery_end  \\\n",
       "0        24050.1     38163.0100 2023-01-01 00:00:00 2023-01-01 01:00:00   \n",
       "1        23886.3     37379.1898 2023-01-01 01:00:00 2023-01-01 02:00:00   \n",
       "2        23366.5     36336.8303 2023-01-01 02:00:00 2023-01-01 03:00:00   \n",
       "3        22829.8     35337.7595 2023-01-01 03:00:00 2023-01-01 04:00:00   \n",
       "4        22347.6     34474.3403 2023-01-01 04:00:00 2023-01-01 05:00:00   \n",
       "\n",
       "   is_test  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw  = pd.read_csv(train_path)\n",
    "test_raw   = pd.read_csv(test_path)\n",
    "sample_sub = pd.read_csv(sample_path)\n",
    "\n",
    "for dfi in [train_raw, test_raw]:\n",
    "    dfi['delivery_start'] = pd.to_datetime(dfi['delivery_start'])\n",
    "    dfi['delivery_end']   = pd.to_datetime(dfi['delivery_end'])\n",
    "\n",
    "train_raw['is_test'] = 0\n",
    "test_raw['is_test']  = 1\n",
    "test_raw['target']   = np.nan\n",
    "\n",
    "df = pd.concat([train_raw, test_raw], ignore_index=True)\n",
    "df = df.sort_values(['market', 'delivery_start']).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_fe1",
   "metadata": {},
   "source": [
    "## Feature Engineering ‚Äî Base & Market Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell_fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Basic time features ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ds = df['delivery_start']\n",
    "df['hour']         = ds.dt.hour\n",
    "df['day_of_week']  = ds.dt.dayofweek\n",
    "df['day_of_month'] = ds.dt.day\n",
    "df['month']        = ds.dt.month\n",
    "df['quarter']      = ds.dt.quarter\n",
    "df['day_of_year']  = ds.dt.dayofyear\n",
    "df['year']         = ds.dt.year\n",
    "df['is_weekend']   = (ds.dt.dayofweek >= 5).astype(np.int8)\n",
    "df['week_of_year'] = ds.dt.isocalendar().week.astype(int)\n",
    "\n",
    "# Cyclical encoding\n",
    "df['hour_sin']        = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos']        = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['month_sin']       = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos']       = np.cos(2 * np.pi * df['month'] / 12)\n",
    "df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "\n",
    "# Market encoding\n",
    "market_map = {f'Market {c}': i for i, c in enumerate('ABCDEF')}\n",
    "df['market_id'] = df['market'].map(market_map).astype(np.int8)\n",
    "\n",
    "# Advanced demand and supply features\n",
    "df['residual_demand']       = df['load_forecast'] - df['solar_forecast'] - df['wind_forecast']\n",
    "df['supply_ratio']          = (df['solar_forecast'] + df['wind_forecast']) / (df['load_forecast'] + 1)\n",
    "df['renewable_ratio']       = (df['solar_forecast'] + df['wind_forecast']) / (df['solar_forecast'] + df['wind_forecast'] + df['load_forecast'] + 1)\n",
    "df['net_supply']            = df['solar_forecast'] + df['wind_forecast']\n",
    "df['demand_supply_balance'] = df['load_forecast'] / (df['solar_forecast'] + df['wind_forecast'] + 1)\n",
    "\n",
    "# Tightness ratios\n",
    "df['tightness_ratio']  = df['residual_demand'] / (df['load_forecast'] + 1)\n",
    "df['tightness_x_month']= df['tightness_ratio'] * df['month']\n",
    "df['tightness_x_hour'] = df['tightness_ratio'] * df['hour']\n",
    "df['tightness_x_dow']  = df['tightness_ratio'] * df['day_of_week']\n",
    "\n",
    "# Price sensitivity\n",
    "df['solar_wind_ratio'] = df['solar_forecast'] / (df['wind_forecast'] + 1)\n",
    "df['wind_solar_ratio'] = df['wind_forecast']  / (df['solar_forecast'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_fe_weather",
   "metadata": {},
   "source": [
    "## Feature Engineering ‚Äî Advanced Weather Physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell_fe_weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Advanced Weather Physics Features ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if 'convective_available_potential_energy' in df.columns:\n",
    "    df['cape'] = df['convective_available_potential_energy']\n",
    "if 'precipitation_amount' in df.columns:\n",
    "    df['precipitation'] = df['precipitation_amount']\n",
    "if 'apparent_temperature_2m' in df.columns:\n",
    "    df['apparent_temperature'] = df['apparent_temperature_2m']\n",
    "if 'freezing_level_height' in df.columns:\n",
    "    df['boundary_layer_height'] = df['freezing_level_height']\n",
    "\n",
    "# Saturation vapour pressure (Tetens formula)\n",
    "es = 6.112 * np.exp((17.67 * df['air_temperature_2m']) / (df['air_temperature_2m'] + 243.5))\n",
    "ea = (df['relative_humidity_2m'] / 100.0) * es\n",
    "df['vapour_pressure_deficit_2m'] = es - ea\n",
    "df['precipitation_probability']  = np.where(df['relative_humidity_2m'] > 85, 50, 0)\n",
    "\n",
    "df['dew_point_depression']    = df['air_temperature_2m'] - df['dew_point_temperature_2m']\n",
    "df['wet_bulb_depression']     = df['air_temperature_2m'] - df['wet_bulb_temperature_2m']\n",
    "df['humidity_ratio']          = (0.622 * df['vapour_pressure_deficit_2m']) / (df['surface_pressure'] - df['vapour_pressure_deficit_2m'])\n",
    "df['blh_normalized_pressure'] = df['boundary_layer_height'] / (df['surface_pressure'] / 1000)\n",
    "\n",
    "# Wind shear\n",
    "df['wind_shear']       = df['wind_speed_80m'] - df['wind_speed_10m']\n",
    "df['wind_shear_ratio'] = df['wind_speed_80m'] / (df['wind_speed_10m'] + 0.1)\n",
    "\n",
    "# Convection indices\n",
    "df['cape_cin_interaction']          = df['cape'] * df['convective_inhibition']\n",
    "df['convection_potential']          = df['cape'] / (abs(df['convective_inhibition']) + 1)\n",
    "df['visibility_cloud_interaction']  = df['visibility'] / (df['cloud_cover_total'] + 1)\n",
    "\n",
    "# Combined weather severity\n",
    "df['weather_severity'] = (\n",
    "    df['cloud_cover_total'] / 100 +\n",
    "    (100 - df['visibility'].clip(0, 100)) / 100 +\n",
    "    df['precipitation_probability'] / 100 +\n",
    "    df['cape'] / 1000\n",
    ") / 4\n",
    "\n",
    "# Solar / wind potential\n",
    "df['solar_potential'] = df['global_horizontal_irradiance'] * (1 - df['cloud_cover_total'] / 100)\n",
    "df['wind_potential']  = df['wind_speed_80m'] ** 3\n",
    "\n",
    "# Extreme weather flags (only extreme_wind kept; extreme_temp/extreme_precip will be pruned)\n",
    "df['extreme_temp']   = ((df['air_temperature_2m'] > 30) | (df['air_temperature_2m'] < -5)).astype(int)\n",
    "df['extreme_wind']   = (df['wind_speed_80m'] > 25).astype(int)\n",
    "df['extreme_precip'] = (df['precipitation'] > 5).astype(int)\n",
    "\n",
    "# Seasonal x weather interactions\n",
    "df['temp_month_interaction'] = df['air_temperature_2m'] * df['month']\n",
    "df['wind_month_interaction'] = df['wind_speed_80m']     * df['month']\n",
    "df['solar_hour_interaction'] = df['solar_forecast']     * df['hour']\n",
    "\n",
    "# Degree-hours\n",
    "df['cooling_degree_hours'] = np.maximum(df['air_temperature_2m'] - 22, 0)\n",
    "df['heating_degree_hours'] = np.maximum(18 - df['air_temperature_2m'], 0)\n",
    "\n",
    "# VPD normalised\n",
    "df['vpd_normalized'] = df['vapour_pressure_deficit_2m'] / df['surface_pressure']\n",
    "\n",
    "# Apparent temperature anomaly\n",
    "df['apparent_temp_anomaly']   = df['apparent_temperature'] - df['air_temperature_2m']\n",
    "df['apparent_air_temp_ratio'] = df['apparent_temperature'] / (df['air_temperature_2m'] + 1)\n",
    "\n",
    "if 'lifted_index' in df.columns:\n",
    "    df['lifted_index_negative'] = (-df['lifted_index']).clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_fe_mom",
   "metadata": {},
   "source": [
    "## Feature Engineering ‚Äî Momentum & Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell_fe_mom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Weather Momentum & Lag Features (NO target leakage) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "weather_cols = ['wind_speed_80m', 'solar_forecast', 'load_forecast',\n",
    "                'wind_forecast', 'air_temperature_2m']\n",
    "\n",
    "for col in weather_cols:\n",
    "    grp = df.groupby('market_id')[col]\n",
    "    df[f'{col}_diff_1h']  = grp.diff(1)\n",
    "    df[f'{col}_diff_3h']  = grp.diff(3)\n",
    "    df[f'{col}_diff_6h']  = grp.diff(6)\n",
    "    df[f'{col}_diff_12h'] = grp.diff(12)\n",
    "    df[f'{col}_rolling_mean_6h']  = grp.transform(lambda x: x.rolling(6,  min_periods=1).mean())\n",
    "    df[f'{col}_rolling_std_6h']   = grp.transform(lambda x: x.rolling(6,  min_periods=1).std().fillna(0))\n",
    "    df[f'{col}_rolling_mean_24h'] = grp.transform(lambda x: x.rolling(24, min_periods=1).mean())\n",
    "    df[f'{col}_rolling_std_24h']  = grp.transform(lambda x: x.rolling(24, min_periods=1).std().fillna(0))\n",
    "    df[f'{col}_rolling_min_24h']  = grp.transform(lambda x: x.rolling(24, min_periods=1).min().bfill())\n",
    "    df[f'{col}_rolling_max_24h']  = grp.transform(lambda x: x.rolling(24, min_periods=1).max().bfill())\n",
    "    df[f'{col}_range_24h']        = df[f'{col}_rolling_max_24h'] - df[f'{col}_rolling_min_24h']\n",
    "    df[f'{col}_ewm_6h']   = grp.transform(lambda x: x.ewm(span=6,  adjust=False).mean())\n",
    "    df[f'{col}_ewm_24h']  = grp.transform(lambda x: x.ewm(span=24, adjust=False).mean())\n",
    "    df[f'{col}_zscore_24h'] = (df[col] - df[f'{col}_rolling_mean_24h']) / (df[f'{col}_rolling_std_24h'] + 0.001)\n",
    "\n",
    "# Temperature anomaly vs recent history\n",
    "df['temp_24h_mean']    = df.groupby('market_id')['air_temperature_2m'].transform(lambda x: x.rolling(24, min_periods=1).mean())\n",
    "df['temp_72h_mean']    = df.groupby('market_id')['air_temperature_2m'].transform(lambda x: x.rolling(72, min_periods=1).mean())\n",
    "df['temp_anomaly_24h'] = df['air_temperature_2m'] - df['temp_24h_mean']\n",
    "df['temp_anomaly_72h'] = df['air_temperature_2m'] - df['temp_72h_mean']\n",
    "\n",
    "# Wind direction\n",
    "df['wind_dir_sin']    = np.sin(np.deg2rad(df['wind_direction_80m']))\n",
    "df['wind_dir_cos']    = np.cos(np.deg2rad(df['wind_direction_80m']))\n",
    "df['wind_dir_change'] = df.groupby('market_id')['wind_direction_80m'].diff(1).abs()\n",
    "\n",
    "# Pressure & humidity interactions\n",
    "df['pressure_temp_interaction'] = df['surface_pressure'] * df['air_temperature_2m']\n",
    "df['humidity_temp_interaction'] = df['relative_humidity_2m'] * df['air_temperature_2m']\n",
    "df['pressure_gradient']         = df.groupby('market_id')['surface_pressure'].diff(1)\n",
    "\n",
    "# Cloud & precipitation\n",
    "df['cloud_cover_total_sq'] = df['cloud_cover_total'] ** 2\n",
    "df['cloud_cover_effect']   = df['cloud_cover_total'] * df['global_horizontal_irradiance']\n",
    "df['precip_prob_sq']       = df['precipitation_probability'] ** 2\n",
    "df['precip_effect']        = df['precipitation'] * df['precipitation_probability']\n",
    "\n",
    "# Radiation efficiency\n",
    "df['solar_efficiency']      = df['solar_forecast'] / (df['global_horizontal_irradiance'] + 1)\n",
    "df['radiation_cloud_ratio'] = df['global_horizontal_irradiance'] / (df['cloud_cover_total'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_fe_temp",
   "metadata": {},
   "source": [
    "## Feature Engineering ‚Äî Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell_fe_temp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Advanced Temporal Features ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "df['hour_from_peak']   = abs(df['hour'] - 12)\n",
    "df['is_peak_solar']    = ((df['hour'] >= 10) & (df['hour'] <= 16)).astype(int)\n",
    "df['is_off_peak']      = ((df['hour'] >= 22) | (df['hour'] <= 6)).astype(int)\n",
    "df['is_business_hours']= ((df['hour'] >= 8) & (df['hour'] <= 18) & (df['day_of_week'] < 5)).astype(int)\n",
    "\n",
    "df['is_monday']       = (df['day_of_week'] == 0).astype(int)\n",
    "df['is_friday']       = (df['day_of_week'] == 4).astype(int)\n",
    "df['is_weekend_start']= (df['day_of_week'] == 4).astype(int)\n",
    "df['is_weekend_end']  = (df['day_of_week'] == 6).astype(int)\n",
    "\n",
    "df['is_winter'] = df['month'].isin([12, 1, 2]).astype(int)\n",
    "df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)\n",
    "df['is_spring'] = df['month'].isin([3, 4, 5]).astype(int)\n",
    "df['is_autumn'] = df['month'].isin([9, 10, 11]).astype(int)\n",
    "\n",
    "df['q1_temp_interaction'] = (df['quarter'] == 1) * df['air_temperature_2m']\n",
    "df['q2_temp_interaction'] = (df['quarter'] == 2) * df['air_temperature_2m']\n",
    "df['q3_temp_interaction'] = (df['quarter'] == 3) * df['air_temperature_2m']\n",
    "df['q4_temp_interaction'] = (df['quarter'] == 4) * df['air_temperature_2m']\n",
    "\n",
    "df['winter_load_factor'] = df['is_winter'] * df['load_forecast']\n",
    "df['summer_load_factor'] = df['is_summer'] * df['load_forecast']\n",
    "df['spring_load_factor'] = df['is_spring'] * df['load_forecast']\n",
    "df['autumn_load_factor'] = df['is_autumn'] * df['load_forecast']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_fe_hist",
   "metadata": {},
   "source": [
    "## Feature Engineering ‚Äî Historical Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell_fe_hist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Safe historical encoding: 7 features\n",
      "   Global training mean: 37.3241\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Historical Target Encoding (Validation-Safe) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "strict_train = df[(df['is_test'] == 0) & (df['delivery_start'] < VAL_PHYSICS_START)]\n",
    "\n",
    "mean_mh  = strict_train.groupby(['market_id','hour'])['target'].mean().reset_index(name='target_histmean_mh')\n",
    "mean_mdow= strict_train.groupby(['market_id','day_of_week'])['target'].mean().reset_index(name='target_histmean_mdow')\n",
    "mean_mm  = strict_train.groupby(['market_id','month'])['target'].mean().reset_index(name='target_histmean_mm')\n",
    "mean_m   = strict_train.groupby(['market_id'])['target'].mean().reset_index(name='target_histmean_m')\n",
    "mean_h   = strict_train.groupby(['hour'])['target'].mean().reset_index(name='target_histmean_h')\n",
    "mean_mhd = strict_train.groupby(['market_id','hour','day_of_week'])['target'].mean().reset_index(name='target_histmean_mhd')\n",
    "mean_mq  = strict_train.groupby(['market_id','quarter'])['target'].mean().reset_index(name='target_histmean_mq')\n",
    "\n",
    "df = df.merge(mean_mh,  on=['market_id','hour'],              how='left')\n",
    "df = df.merge(mean_mdow,on=['market_id','day_of_week'],       how='left')\n",
    "df = df.merge(mean_mm,  on=['market_id','month'],             how='left')\n",
    "df = df.merge(mean_m,   on=['market_id'],                     how='left')\n",
    "df = df.merge(mean_h,   on=['hour'],                          how='left')\n",
    "df = df.merge(mean_mhd, on=['market_id','hour','day_of_week'],how='left')\n",
    "df = df.merge(mean_mq,  on=['market_id','quarter'],           how='left')\n",
    "\n",
    "global_mean = strict_train['target'].mean()\n",
    "for c in [c for c in df.columns if c.startswith('target_histmean_')]:\n",
    "    df[c] = df[c].fillna(global_mean)\n",
    "\n",
    "df['histmean_mh_x_residual']      = df['target_histmean_mh'] * df['residual_demand']\n",
    "df['histmean_mh_x_tightness']     = df['target_histmean_mh'] * df['tightness_ratio']\n",
    "df['histmean_deviation_dow_vs_m'] = df['target_histmean_mdow'] - df['target_histmean_m']\n",
    "df['histmean_deviation_mh_vs_h']  = df['target_histmean_mh']  - df['target_histmean_h']\n",
    "\n",
    "print(f'‚úÖ Safe historical encoding: {sum(c.startswith(\"target_histmean\") for c in df.columns)} features')\n",
    "print(f'   Global training mean: {global_mean:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_fe_inter",
   "metadata": {},
   "source": [
    "## Feature Engineering ‚Äî Interactions & Final NaN Fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell_fe_inter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature engineering complete: 240 total columns\n",
      "   Training rows: 132608, Test rows: 13098\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Interaction features ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "df['temp_load_interaction']  = df['air_temperature_2m'] * df['load_forecast']\n",
    "df['wind_load_interaction']  = df['wind_speed_80m']     * df['load_forecast']\n",
    "df['solar_load_interaction'] = df['solar_forecast']     * df['load_forecast']\n",
    "df['temp_wind_interaction']  = df['air_temperature_2m'] * df['wind_speed_80m']\n",
    "df['temp_solar_interaction'] = df['air_temperature_2m'] * df['solar_forecast']\n",
    "df['wind_solar_interaction'] = df['wind_speed_80m']     * df['solar_forecast']\n",
    "\n",
    "df['temp_wind_load_interaction']  = df['air_temperature_2m'] * df['wind_speed_80m'] * df['load_forecast']\n",
    "df['temp_solar_load_interaction'] = df['air_temperature_2m'] * df['solar_forecast'] * df['load_forecast']\n",
    "df['wind_solar_load_interaction'] = df['wind_speed_80m']     * df['solar_forecast'] * df['load_forecast']\n",
    "\n",
    "df['temp_volatility']  = df.groupby('market_id')['air_temperature_2m'].transform(lambda x: x.rolling(24, min_periods=1).std().fillna(0))\n",
    "df['wind_volatility']  = df.groupby('market_id')['wind_speed_80m'].transform(lambda x: x.rolling(24, min_periods=1).std().fillna(0))\n",
    "df['solar_volatility'] = df.groupby('market_id')['solar_forecast'].transform(lambda x: x.rolling(24, min_periods=1).std().fillna(0))\n",
    "\n",
    "df['temp_rate_change']  = df.groupby('market_id')['air_temperature_2m'].diff(1) / (df.groupby('market_id')['air_temperature_2m'].shift(1).abs() + 0.01)\n",
    "df['wind_rate_change']  = df.groupby('market_id')['wind_speed_80m'].diff(1)     / (df.groupby('market_id')['wind_speed_80m'].shift(1).abs() + 0.01)\n",
    "df['solar_rate_change'] = df.groupby('market_id')['solar_forecast'].diff(1)     / (df.groupby('market_id')['solar_forecast'].shift(1).abs() + 0.01)\n",
    "\n",
    "for col in ['wind_speed_80m', 'solar_forecast', 'load_forecast']:\n",
    "    ts_mean = df.groupby('delivery_start')[col].transform('mean')\n",
    "    ts_std  = df.groupby('delivery_start')[col].transform('std') + 0.001\n",
    "    df[f'{col}_market_diff']   = df[col] - ts_mean\n",
    "    df[f'{col}_market_zscore'] = (df[col] - ts_mean) / ts_std\n",
    "\n",
    "for col in ['wind_speed_80m', 'solar_forecast', 'load_forecast']:\n",
    "    df[f'{col}_skew_24h'] = df.groupby('market_id')[col].transform(\n",
    "        lambda x: x.rolling(24, min_periods=12).skew().fillna(0))\n",
    "\n",
    "# Summer heatwave & grid stress\n",
    "df['heatwave_stress'] = np.where(\n",
    "    (df['air_temperature_2m'] > 25) & (df['wind_speed_80m'] < 5),\n",
    "    (df['air_temperature_2m'] - 25) ** 2, 0)\n",
    "df['renewable_drought'] = ((df['solar_forecast'] < 10) & (df['wind_forecast'] < 10)).astype(int)\n",
    "df['cooling_degree_load'] = df['load_forecast'] * np.maximum(0, df['air_temperature_2m'] - 22)\n",
    "\n",
    "# Winter physics & grid stress\n",
    "df['heating_degree_load'] = df['load_forecast'] * np.maximum(0, 18 - df['air_temperature_2m'])\n",
    "df['wind_cutout_risk']    = (df['wind_speed_80m'] > 22).astype(int)\n",
    "df['wind_cutout_penalty'] = df['wind_cutout_risk'] * df['residual_demand']\n",
    "\n",
    "df['dark_cold_stress'] = np.where(\n",
    "    (df['air_temperature_2m'] < 5) & (df['solar_forecast'] < 10) & (df['wind_speed_80m'] < 5),\n",
    "    (5 - df['air_temperature_2m']) * df['load_forecast'], 0)\n",
    "\n",
    "df['wind_chill_proxy'] = np.where(\n",
    "    df['air_temperature_2m'] < 10,\n",
    "    df['air_temperature_2m'] - (df['wind_speed_80m'] * 0.5),\n",
    "    df['air_temperature_2m'])\n",
    "\n",
    "# Final NaN fill\n",
    "exclude_from_fill = {'target', 'delivery_start', 'delivery_end', 'market', 'id'}\n",
    "for col in df.columns:\n",
    "    if col in exclude_from_fill: continue\n",
    "    if df[col].dtype in ['float64', 'float32', 'int64', 'int32', 'int8']:\n",
    "        nan_count = df[col].isna().sum()\n",
    "        if nan_count > 0:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "print(f'‚úÖ Feature engineering complete: {len(df.columns)} total columns')\n",
    "print(f'   Training rows: {(df[\"is_test\"]==0).sum()}, Test rows: {(df[\"is_test\"]==1).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_prune",
   "metadata": {},
   "source": [
    "## MOD 1: Feature Pruning (Useless + Correlated > 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell_prune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PRUNING USELESS FEATURES ---\n",
      "  Dropped 20 useless features\n",
      "\n",
      "--- PRUNING CORRELATED FEATURES ---\n",
      "  Dropped 33 correlated features\n",
      "  Remaining columns: 187\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ MOD 1: Feature Pruning ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print('--- PRUNING USELESS FEATURES ---')\n",
    "useless_features = [\n",
    "    'precip_prob_sq', 'precipitation', 'load_forecast_market_zscore',\n",
    "    'load_forecast_market_diff', 'extreme_temp', 'extreme_precip',\n",
    "    'is_off_peak', 'heatwave_stress', 'dark_cold_stress', 'precip_effect',\n",
    "    'quarter', 'solar_forecast_rolling_min_24h', 'renewable_drought',\n",
    "    'precipitation_amount', 'precipitation_probability', 'is_summer',\n",
    "    'is_autumn', 'is_monday', 'hour_from_peak', 'is_peak_solar'\n",
    "]\n",
    "actual_drops = [c for c in useless_features if c in df.columns]\n",
    "df.drop(columns=actual_drops, inplace=True)\n",
    "print(f'  Dropped {len(actual_drops)} useless features')\n",
    "\n",
    "print('\\n--- PRUNING CORRELATED FEATURES ---')\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "if 'target' in numeric_cols: numeric_cols = numeric_cols.drop('target')\n",
    "corr_matrix = df[numeric_cols].corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop_corr = [column for column in upper.columns if any(upper[column] > 0.98)]\n",
    "df.drop(columns=to_drop_corr, inplace=True)\n",
    "print(f'  Dropped {len(to_drop_corr)} correlated features')\n",
    "print(f'  Remaining columns: {len(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_split",
   "metadata": {},
   "source": [
    "## MOD 2+3: Unified Train/Val Split + Categorical Casting + Winter Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell_split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Categorical columns: ['market_id', 'hour', 'day_of_week', 'month']\n",
      "üå≤ X_train:       101,792\n",
      "‚ùÑÔ∏è X_val_physics: 17,568\n",
      "üì¶ X_all:         132,608\n",
      "üî¨ X_test:        13,098\n",
      "‚öñÔ∏è Winter-weighted rows (train): 15,769\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ MOD 2+3: Unified Split + Categorical Columns + Winter Weights ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "observed_df = df[df['is_test'] == 0].copy()\n",
    "test_df     = df[df['is_test'] == 1].copy()\n",
    "\n",
    "mask_val_physics = (observed_df['delivery_start'] >= VAL_PHYSICS_START) & (observed_df['delivery_start'] < VAL_PHYSICS_END)\n",
    "mask_val_recency = (observed_df['delivery_start'] >= VAL_RECENCY_START)\n",
    "mask_train       = ~(mask_val_physics | mask_val_recency)\n",
    "\n",
    "train_df       = observed_df[mask_train]\n",
    "val_physics_df = observed_df[mask_val_physics]\n",
    "\n",
    "drop_cols = {'id', 'target', 'market', 'delivery_start', 'delivery_end', 'is_test'}\n",
    "feat_cols = sorted([c for c in df.columns if c not in drop_cols])\n",
    "\n",
    "# Declare categoricals explicitly (only those remaining after pruning)\n",
    "cat_cols = [c for c in ['market_id', 'hour', 'day_of_week', 'month'] if c in feat_cols]\n",
    "print(f'  Categorical columns: {cat_cols}')\n",
    "\n",
    "X_train       = train_df[feat_cols].copy()\n",
    "y_train_real  = train_df['target'].values\n",
    "y_train       = np.arcsinh(train_df['target'].values)\n",
    "\n",
    "X_val_physics      = val_physics_df[feat_cols].copy()\n",
    "y_val_physics_real = val_physics_df['target'].values\n",
    "y_val_physics      = np.arcsinh(val_physics_df['target'].values)\n",
    "\n",
    "X_all  = observed_df[feat_cols].copy()\n",
    "y_all  = np.arcsinh(observed_df['target'].values)\n",
    "\n",
    "X_test = test_df[feat_cols].copy()\n",
    "\n",
    "# Cast categoricals to 'category' dtype\n",
    "for ds in [X_train, X_val_physics, X_all, X_test]:\n",
    "    for c in cat_cols:\n",
    "        ds[c] = ds[c].astype('category')\n",
    "\n",
    "# MOD 3: Winter weights ‚Äî months 9-12 get 3x weight\n",
    "train_month_vals = train_df['month'].values\n",
    "train_weights = np.where(np.isin(train_month_vals, [9, 10, 11, 12]), 3.0, 1.0)\n",
    "\n",
    "all_month_vals = observed_df['month'].values\n",
    "all_weights = np.where(np.isin(all_month_vals, [9, 10, 11, 12]), 3.0, 1.0)\n",
    "\n",
    "print(f'üå≤ X_train:       {len(X_train):,}')\n",
    "print(f'‚ùÑÔ∏è X_val_physics: {len(X_val_physics):,}')\n",
    "print(f'üì¶ X_all:         {len(X_all):,}')\n",
    "print(f'üî¨ X_test:        {len(X_test):,}')\n",
    "print(f'‚öñÔ∏è Winter-weighted rows (train): {(train_weights==3.0).sum():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_lgb",
   "metadata": {},
   "source": [
    "## BLOCK A ‚Äî LightGBM Optuna (Unified + Winter Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell_lgb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BLOCK A: LightGBM\n",
      "============================================================\n",
      "  Best LGB RMSE=47.4800\n",
      "  LGB done in 1272s\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ BLOCK A: LightGBM Optuna (Unified + Winter Weights) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "t0 = time.time()\n",
    "print('='*60); print('BLOCK A: LightGBM'); print('='*60)\n",
    "\n",
    "cat_idx_lgb = [feat_cols.index(c) for c in cat_cols]\n",
    "\n",
    "def _lgb_obj(trial):\n",
    "    p = {'objective':'huber','metric':'rmse','verbosity':-1,'seed':SEED,'n_jobs':-1,\n",
    "         'learning_rate': trial.suggest_float('lr', 1e-3, 0.1, log=True),\n",
    "         'num_leaves':    trial.suggest_int('nl', 31, 512),\n",
    "         'alpha':         trial.suggest_float('alpha', 1.0, 3.0)}\n",
    "    ds_t = lgb.Dataset(X_train, y_train, categorical_feature=cat_idx_lgb,\n",
    "                        weight=train_weights, free_raw_data=False)\n",
    "    ds_v = lgb.Dataset(X_val_physics, y_val_physics, reference=ds_t, free_raw_data=False)\n",
    "    m = lgb.train(p, ds_t, 2000, valid_sets=[ds_v],\n",
    "                  callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "    trial.set_user_attr('bi', m.best_iteration)\n",
    "    preds = np.sinh(np.clip(m.predict(X_val_physics), -20, 20))\n",
    "    return root_mean_squared_error(y_val_physics_real, preds)\n",
    "\n",
    "s_lgb = optuna.create_study(direction='minimize')\n",
    "s_lgb.optimize(_lgb_obj, n_trials=N_TRIALS)\n",
    "print(f'  Best LGB RMSE={s_lgb.best_value:.4f}')\n",
    "\n",
    "bi_lgb = s_lgb.best_trial.user_attrs['bi']\n",
    "_p = {'objective':'huber','metric':'rmse','verbosity':-1,'seed':SEED,'n_jobs':-1,\n",
    "      'learning_rate': s_lgb.best_params['lr'],\n",
    "      'num_leaves':    s_lgb.best_params['nl'],\n",
    "      'alpha':         s_lgb.best_params['alpha']}\n",
    "val_lgb = lgb.train(_p,\n",
    "    lgb.Dataset(X_train, y_train, categorical_feature=cat_idx_lgb, weight=train_weights),\n",
    "    bi_lgb)\n",
    "val_lgb.save_model('../models/v14/lgb_val.txt')\n",
    "json.dump({'params': s_lgb.best_params, 'bi': bi_lgb},\n",
    "          open('../models/v14/lgb_params.json', 'w'))\n",
    "print(f'  LGB done in {time.time()-t0:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_xgb",
   "metadata": {},
   "source": [
    "## BLOCK B ‚Äî XGBoost Optuna (Unified + Winter Weights + Safe Huber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell_xgb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BLOCK B: XGBoost\n",
      "============================================================\n",
      "  Best XGB RMSE=46.6466\n",
      "  XGB done in 3666s\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ BLOCK B: XGBoost Optuna (Unified + Winter Weights + Safe Huber) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "t0 = time.time()\n",
    "print('='*60); print('BLOCK B: XGBoost'); print('='*60)\n",
    "\n",
    "# XGBoost needs numeric categories\n",
    "def _to_xgb(X):\n",
    "    Xc = X.copy()\n",
    "    for c in cat_cols:\n",
    "        Xc[c] = Xc[c].cat.codes\n",
    "    return Xc\n",
    "\n",
    "dt_xgb = xgb.DMatrix(_to_xgb(X_train), label=y_train, weight=train_weights)\n",
    "dv_xgb = xgb.DMatrix(_to_xgb(X_val_physics), label=y_val_physics)\n",
    "\n",
    "def _xgb_obj(trial):\n",
    "    p = {\n",
    "        'tree_method': 'hist',\n",
    "        'objective':   'reg:pseudohubererror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'huber_slope': trial.suggest_float('alpha', 1.0, 3.0),\n",
    "        'seed':        SEED,\n",
    "        'n_jobs':      -1,\n",
    "        'learning_rate': trial.suggest_float('lr', 1e-3, 0.1, log=True),\n",
    "        'max_depth':     trial.suggest_int('md', 5, 12)\n",
    "    }\n",
    "    m = xgb.train(p, dt_xgb, 2000, evals=[(dv_xgb,'v')],\n",
    "                  early_stopping_rounds=50, verbose_eval=False)\n",
    "    trial.set_user_attr('bi', m.best_iteration)\n",
    "    preds = np.sinh(np.clip(m.predict(dv_xgb), -20, 20))\n",
    "    return root_mean_squared_error(y_val_physics_real, preds)\n",
    "\n",
    "s_xgb = optuna.create_study(direction='minimize')\n",
    "s_xgb.optimize(_xgb_obj, n_trials=N_TRIALS)\n",
    "print(f'  Best XGB RMSE={s_xgb.best_value:.4f}')\n",
    "\n",
    "bi_xgb = s_xgb.best_trial.user_attrs['bi']\n",
    "_p = {'tree_method':'hist','objective':'reg:pseudohubererror',\n",
    "      'eval_metric':'rmse','seed':SEED,'n_jobs':-1,\n",
    "      'learning_rate': s_xgb.best_params['lr'],\n",
    "      'max_depth':     s_xgb.best_params['md'],\n",
    "      'huber_slope':   s_xgb.best_params['alpha']}\n",
    "val_xgb = xgb.train(_p, dt_xgb, bi_xgb, evals=[(dv_xgb,'v')], verbose_eval=False)\n",
    "val_xgb.save_model('../models/v14/xgb_val.json')\n",
    "json.dump({'params': s_xgb.best_params, 'bi': bi_xgb},\n",
    "          open('../models/v14/xgb_params.json', 'w'))\n",
    "print(f'  XGB done in {time.time()-t0:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_cat",
   "metadata": {},
   "source": [
    "## BLOCK C ‚Äî CatBoost Optuna (Unified + Winter Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell_cat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BLOCK C: CatBoost\n",
      "============================================================\n",
      "  Best CAT RMSE=49.2251\n",
      "  CAT done in 2228s\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ BLOCK C: CatBoost Optuna (Unified + Winter Weights) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "t0 = time.time()\n",
    "print('='*60); print('BLOCK C: CatBoost'); print('='*60)\n",
    "\n",
    "cat_feat_idx = [list(X_train.columns).index(c) for c in cat_cols]\n",
    "\n",
    "def _cat_obj(trial):\n",
    "    p = {'loss_function':'Huber:delta=1.5','task_type':'CPU','eval_metric':'RMSE',\n",
    "         'random_seed':SEED,'verbose':False,'iterations':1000,'early_stopping_rounds':50,\n",
    "         'learning_rate': trial.suggest_float('lr', 1e-3, 0.1, log=True),\n",
    "         'depth':         trial.suggest_int('depth', 4, 10)}\n",
    "    m = CatBoostRegressor(**p)\n",
    "    m.fit(Pool(X_train, y_train, cat_features=cat_feat_idx, weight=train_weights),\n",
    "          eval_set=Pool(X_val_physics, y_val_physics, cat_features=cat_feat_idx),\n",
    "          use_best_model=True)\n",
    "    trial.set_user_attr('bi', m.get_best_iteration())\n",
    "    preds = np.sinh(np.clip(m.predict(X_val_physics), -20, 20))\n",
    "    return root_mean_squared_error(y_val_physics_real, preds)\n",
    "\n",
    "s_cat = optuna.create_study(direction='minimize')\n",
    "s_cat.optimize(_cat_obj, n_trials=15)\n",
    "print(f'  Best CAT RMSE={s_cat.best_value:.4f}')\n",
    "\n",
    "bi_cat = s_cat.best_trial.user_attrs['bi']\n",
    "_p = {'loss_function':'Huber:delta=1.5','task_type':'CPU','eval_metric':'RMSE',\n",
    "      'random_seed':SEED,'verbose':False,'iterations':bi_cat,\n",
    "      'learning_rate': s_cat.best_params['lr'],\n",
    "      'depth':         s_cat.best_params['depth']}\n",
    "val_cat = CatBoostRegressor(**_p)\n",
    "val_cat.fit(Pool(X_train, y_train, cat_features=cat_feat_idx, weight=train_weights),\n",
    "            eval_set=Pool(X_val_physics, y_val_physics, cat_features=cat_feat_idx),\n",
    "            use_best_model=True)\n",
    "val_cat.save_model('../models/v14/cat_val.cbm')\n",
    "json.dump({'params': s_cat.best_params, 'bi': bi_cat},\n",
    "          open('../models/v14/cat_params.json', 'w'))\n",
    "print(f'  CAT done in {time.time()-t0:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_scipy",
   "metadata": {},
   "source": [
    "## BLOCK D ‚Äî SciPy Global Ensemble Weight Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell_scipy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BLOCK D: SCIPY WEIGHT OPTIMIZATION\n",
      "============================================================\n",
      "  Global weights [LGB, XGB, CAT]: [0.129 0.871 0.   ]\n",
      "  Val Physics RMSE: 46.6241\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ BLOCK D: SciPy Global Ensemble Weight Optimization ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print('='*60); print('BLOCK D: SCIPY WEIGHT OPTIMIZATION'); print('='*60)\n",
    "\n",
    "# Predict on full validation set using unified val models\n",
    "# All predictions wrapped in np.sinh(np.clip(..., -20, 20))\n",
    "vp_lgb = np.sinh(np.clip(val_lgb.predict(X_val_physics), -20, 20))\n",
    "vp_xgb = np.sinh(np.clip(val_xgb.predict(xgb.DMatrix(_to_xgb(X_val_physics))), -20, 20))\n",
    "vp_cat = np.sinh(np.clip(val_cat.predict(X_val_physics), -20, 20))\n",
    "\n",
    "def _blend_rmse(w, p1, p2, p3, y_real):\n",
    "    return root_mean_squared_error(y_real, w[0]*p1 + w[1]*p2 + w[2]*p3)\n",
    "\n",
    "cons = {'type':'eq','fun': lambda w: w.sum()-1.0}\n",
    "bnd  = [(0, 1)] * 3\n",
    "w0   = [1/3, 1/3, 1/3]\n",
    "\n",
    "res = sp_minimize(_blend_rmse, w0,\n",
    "                  args=(vp_lgb, vp_xgb, vp_cat, y_val_physics_real),\n",
    "                  method='SLSQP', bounds=bnd, constraints=cons)\n",
    "\n",
    "best_w = res.x\n",
    "print(f'  Global weights [LGB, XGB, CAT]: {np.round(best_w, 4)}')\n",
    "print(f'  Val Physics RMSE: {res.fun:.4f}')\n",
    "json.dump({'weights': best_w.tolist()},\n",
    "          open('../models/v14/ensemble_weights.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_retrain",
   "metadata": {},
   "source": [
    "## BLOCK E ‚Äî Full Retraining on All Observed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell_retrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BLOCK E: FULL RETRAINING\n",
      "============================================================\n",
      "  All 3 unified final models saved.\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ BLOCK E: Full Retraining on All Observed Data (Unified + Winter Weights) ‚îÄ‚îÄ\n",
    "print('='*60); print('BLOCK E: FULL RETRAINING'); print('='*60)\n",
    "\n",
    "cat_idx_lgb_all = [list(X_all.columns).index(c) for c in cat_cols]\n",
    "\n",
    "# ‚îÄ‚îÄ LGB final ‚îÄ‚îÄ\n",
    "_p = {'objective':'huber','metric':'rmse','verbosity':-1,'seed':SEED,'n_jobs':-1,\n",
    "      'learning_rate': s_lgb.best_params['lr'],\n",
    "      'num_leaves':    s_lgb.best_params['nl'],\n",
    "      'alpha':         s_lgb.best_params['alpha']}\n",
    "lgb_final = lgb.train(_p,\n",
    "    lgb.Dataset(X_all, y_all, categorical_feature=cat_idx_lgb_all, weight=all_weights),\n",
    "    num_boost_round=int(bi_lgb * 1.1))\n",
    "lgb_final.save_model('../models/v14/lgb_final.txt')\n",
    "\n",
    "# ‚îÄ‚îÄ XGB final ‚îÄ‚îÄ\n",
    "da_xgb = xgb.DMatrix(_to_xgb(X_all), label=y_all, weight=all_weights)\n",
    "_p = {'tree_method':'hist','objective':'reg:pseudohubererror',\n",
    "      'eval_metric':'rmse','seed':SEED,'n_jobs':-1,\n",
    "      'learning_rate': s_xgb.best_params['lr'],\n",
    "      'max_depth':     s_xgb.best_params['md'],\n",
    "      'huber_slope':   s_xgb.best_params['alpha']}\n",
    "xgb_final = xgb.train(_p, da_xgb, num_boost_round=int(bi_xgb * 1.1))\n",
    "xgb_final.save_model('../models/v14/xgb_final.json')\n",
    "\n",
    "# ‚îÄ‚îÄ CAT final ‚îÄ‚îÄ\n",
    "_p = {'loss_function':'Huber:delta=1.5','task_type':'CPU','random_seed':SEED,'verbose':False,\n",
    "      'learning_rate': s_cat.best_params['lr'],\n",
    "      'depth':         s_cat.best_params['depth'],\n",
    "      'iterations':    int(bi_cat * 1.1)}\n",
    "cat_final = CatBoostRegressor(**_p)\n",
    "cat_final.fit(Pool(X_all, y_all, cat_features=cat_feat_idx, weight=all_weights))\n",
    "cat_final.save_model('../models/v14/cat_final.cbm')\n",
    "\n",
    "print('  All 3 unified final models saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_infer",
   "metadata": {},
   "source": [
    "## BLOCK F ‚Äî Ensemble Inference & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell_infer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BLOCK F: ENSEMBLE INFERENCE\n",
      "============================================================\n",
      "‚úÖ Saved: ../submissions/submission_v14_ultimate_unified_ensemble.csv\n",
      "   Mean:   29.9968\n",
      "   Std:    25.5895\n",
      "   Min:    -22.6493\n",
      "   Max:    259.4966\n",
      "   Median: 26.912\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ BLOCK F: Ensemble Inference & Submission ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print('='*60); print('BLOCK F: ENSEMBLE INFERENCE'); print('='*60)\n",
    "\n",
    "# LGB predictions on test\n",
    "tst_lgb = np.sinh(np.clip(lgb_final.predict(X_test), -20, 20))\n",
    "\n",
    "# XGB predictions on test\n",
    "tst_xgb = np.sinh(np.clip(xgb_final.predict(xgb.DMatrix(_to_xgb(X_test))), -20, 20))\n",
    "\n",
    "# CAT predictions on test\n",
    "tst_cat = np.sinh(np.clip(cat_final.predict(X_test), -20, 20))\n",
    "\n",
    "# Combine using global SciPy-optimal weights\n",
    "final_preds = best_w[0]*tst_lgb + best_w[1]*tst_xgb + best_w[2]*tst_cat\n",
    "# Safety re-clip on combined predictions\n",
    "final_preds = np.sinh(np.clip(np.arcsinh(final_preds), -20, 20))\n",
    "\n",
    "# Build submission\n",
    "pred_df    = pd.DataFrame({'id': test_df['id'].values, 'target': final_preds})\n",
    "submission = sample_sub[['id']].merge(pred_df, on='id', how='left')\n",
    "\n",
    "assert len(submission) == len(sample_sub)\n",
    "assert submission['target'].isna().sum() == 0\n",
    "assert (submission['id'] == sample_sub['id']).all()\n",
    "\n",
    "path = '../submissions/submission_v14_ultimate_unified_ensemble.csv'\n",
    "submission.to_csv(path, index=False)\n",
    "\n",
    "print('‚úÖ Saved:', path)\n",
    "print('   Mean:  ', round(submission['target'].mean(), 4))\n",
    "print('   Std:   ', round(submission['target'].std(),  4))\n",
    "print('   Min:   ', round(submission['target'].min(),  4))\n",
    "print('   Max:   ', round(submission['target'].max(),  4))\n",
    "print('   Median:', round(submission['target'].median(), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nitor_kuas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
